{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairLogReg(nn.Module):\n",
    "    def __init__(self, D, warm_start = None):\n",
    "        super(FairLogReg, self).__init__()\n",
    "        if warm_start is not None:\n",
    "            self.theta = torch.nn.Parameter(warm_start, requires_grad=True)\n",
    "        else:\n",
    "            self.theta = torch.nn.Parameter(torch.zeros(D), requires_grad=True)\n",
    "        self.old_theta = tensor(float(\"Inf\"))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.mv(self.theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick between COMPAS and Adult data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment one out\n",
    "\n",
    "def get_data(filename):\n",
    "    df = pd.read_csv(\"data/COMPAS/\" + filename + \".csv\")\n",
    "    s = tensor(df['race'] == \"Caucasian\")\n",
    "    y = tensor(df['two_year_recid'] == 0).float()\n",
    "    X = tensor(df.drop(columns=['race','sex','sex-race','two_year_recid']).values).float()\n",
    "    X = torch.cat((torch.ones(X.shape[0],1), X), dim=1)\n",
    "    return (X,y,s)\n",
    "lam_regs = 2. ** np.array([-3, -3, -3, -3, -3])\n",
    "\n",
    "def get_data(filename):\n",
    "    df = pd.read_csv(\"data/Adult/\" + filename + \".csv\")\n",
    "    s = tensor(df['sex'] == \"Male\")\n",
    "    y = tensor(df['income-per-year'] == \">50K\").float()\n",
    "    X = tensor(df.drop(columns=['sex','race','income-per-year','race-sex','capital-gain', 'capital-loss']).values).float()\n",
    "    X = torch.cat((torch.ones(X.shape[0],1), X), dim=1)\n",
    "    return (X,y,s)\n",
    "lam_regs = 2. ** np.array([-14, -12, -12, -12, -13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "form=\"linear\"\n",
    "sum_form=1 # 1 for sum, -1 for difference\n",
    "eoo=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if form == \"logistic\":\n",
    "    def g(outputs):\n",
    "        return -F.logsigmoid(-outputs).sum()\n",
    "elif form == \"hinge\":\n",
    "    relu = torch.nn.ReLU()\n",
    "    def g(outputs):\n",
    "        return relu(outputs+1).sum()\n",
    "elif form == \"linear\":\n",
    "    def g(outputs):\n",
    "        return outputs.sum()\n",
    "else:\n",
    "    raise ValueError(\"Pick a valid form!\")\n",
    "\n",
    "ploss = nn.BCEWithLogitsLoss()\n",
    "def floss(outputs, sens_attr, Pa, Pb):\n",
    "    return sum_form * g(sum_form * outputs[sens_attr])/Pa + g(- outputs[~sens_attr])/Pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xs, ys, ss) = ([None] * 5, [None] * 5, [None] * 5)\n",
    "(Xts, yts, sts) = ([None] * 5, [None] * 5, [None] * 5)\n",
    "for i in range(5):\n",
    "    (Xs[i], ys[i], ss[i]) = get_data(\"train\" + str(i))\n",
    "    (Xts[i], yts[i], sts[i]) = get_data(\"test\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_closure(model, optimizer, lam_fair, lam_reg, X, y, s, Pa, Pb):\n",
    "    def closure():\n",
    "        assert not torch.isnan(model.theta).any()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        if eoo:\n",
    "            loss = ploss(outputs,y) + lam_reg * (model.theta**2).mean() + lam_fair/outputs.shape[0] * floss(outputs[y.bool()], s[y.bool()], Pa, Pb)\n",
    "        else:\n",
    "            loss = ploss(outputs,y) + lam_reg * (model.theta**2).mean() + lam_fair/outputs.shape[0] * floss(outputs, s, Pa, Pb)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    return closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X,y,s,lam_fair=0, lam_reg=0, warm_start=None):\n",
    "    if eoo:\n",
    "        (Pa, Pb) = ((s & y.bool()).float().mean(), (~s&y.bool()).float().mean())\n",
    "    else:\n",
    "        (Pa, Pb) = (s.float().mean(), 1 - s.float().mean())\n",
    "    model = FairLogReg(X.shape[1], warm_start=warm_start)\n",
    "    if form == \"hingexxx\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "    else:\n",
    "        optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1)\n",
    "    closure = make_closure(model, optimizer, lam_fair, lam_reg, X, y, s, Pa, Pb)\n",
    "    for t in trange(500):\n",
    "        loss = optimizer.step(closure)\n",
    "        if form == \"hingexxx\":\n",
    "            scheduler.step(loss)\n",
    "        diff = (model.old_theta - model.theta).abs().max()\n",
    "        if diff < 1e-10:\n",
    "            break\n",
    "        model.old_theta = model.theta.clone().detach()\n",
    "    return (model, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(model, X,y,s, lam_fair=0, lam_reg=0):\n",
    "    (Pa, Pb) = (s.float().mean(), 1 - s.float().mean())\n",
    "    outputs = model(X)\n",
    "    accuracy = (y == (outputs >= 0)).float().mean()\n",
    "    if eoo:\n",
    "        unfairness = (outputs[y.bool() & s] >= 0).float().mean() - (outputs[y.bool() & ~s] >= 0).float().mean()\n",
    "        relaxation = 1/outputs.shape[0] * floss(outputs[y.bool()], s[y.bool()], Pa, Pb)\n",
    "    else:\n",
    "        unfairness = (outputs[s] >= 0).float().mean() - (outputs[~s] >= 0).float().mean()\n",
    "        relaxation = 1/outputs.shape[0] * floss(outputs, s, Pa, Pb)\n",
    "    loss = ploss(outputs,y)\n",
    "    return(accuracy, unfairness, loss, relaxation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for weighting baseline, if desired\n",
    "def get_weighed_loss(X,y,s):\n",
    "    wobs = y * 10 + s\n",
    "    wobs[wobs==0.] = (wobs==0.).float().mean()\n",
    "    wobs[wobs==1.] = (wobs==1.).float().mean()\n",
    "    wobs[wobs==11.] = (wobs==11.).float().mean()\n",
    "    wobs[wobs==10.] = (wobs==10.).float().mean()\n",
    "    wy = (y - (y==0).float().mean()).abs()\n",
    "    ws = (s.float() - (s==0).float().mean()).abs()\n",
    "    wexp = ws * wy\n",
    "    return nn.BCEWithLogitsLoss(weight = (wexp/wobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 46/500 [00:00<00:08, 50.71it/s]\n",
      "  8%|▊         | 39/500 [00:00<00:09, 50.00it/s]\n",
      "  4%|▍         | 22/500 [00:00<00:14, 34.12it/s]\n",
      "  7%|▋         | 35/500 [00:00<00:09, 48.91it/s]\n",
      " 12%|█▏        | 61/500 [00:00<00:06, 64.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Split', 'Lam_fair', 'Type', 'Accuracy', 'Unfairness', 'Ploss', 'Relaxation'])\n",
    "warm_starts = [None] * 5\n",
    "lfs = np.arange(0, 0.195, 1) #0.02)\n",
    "for lam_fair in lfs:\n",
    "    for i in range(5):\n",
    "        (model,t) = train_model(Xs[i],ys[i],ss[i], lam_fair = lam_fair, lam_reg = lam_regs[i], warm_start=warm_starts[i])\n",
    "        warm_starts[i] = model.theta.clone().detach()\n",
    "        (train_accuracy, train_unfairness, train_loss, train_relax) = get_summary(model, Xs[i], ys[i], ss[i], lam_fair = lam_fair, lam_reg = lam_regs[i])\n",
    "        d = {\"Split\": i,\n",
    "             \"Type\": \"Train\",\n",
    "             \"Lam_fair\": lam_fair.item(),\n",
    "             'Accuracy': train_accuracy.item(), \n",
    "             'Unfairness': train_unfairness.item(),\n",
    "             'Ploss': train_loss.item(),\n",
    "             'Relaxation': train_relax.item()}\n",
    "        df = df.append(d,ignore_index=True)\n",
    "        (test_accuracy, test_unfairness, test_loss, test_relax) = get_summary(model, Xts[i], yts[i], sts[i], lam_fair = lam_fair, lam_reg = lam_regs[i])\n",
    "        d = {\"Split\": i,\n",
    "             \"Type\": \"Test\",\n",
    "             \"Lam_fair\": lam_fair.item(),\n",
    "             'Accuracy': test_accuracy.item(), \n",
    "             'Unfairness': test_unfairness.item(),\n",
    "             'Ploss': test_loss.item(),\n",
    "             'Relaxation': test_relax.item()}\n",
    "        df = df.append(d,ignore_index=True)\n",
    "    print(lam_fair)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Lam_fair</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Unfairness</th>\n",
       "      <th>Ploss</th>\n",
       "      <th>Relaxation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.081045</td>\n",
       "      <td>0.364729</td>\n",
       "      <td>0.907473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.822383</td>\n",
       "      <td>0.086585</td>\n",
       "      <td>0.377499</td>\n",
       "      <td>0.949487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.827098</td>\n",
       "      <td>0.085512</td>\n",
       "      <td>0.367405</td>\n",
       "      <td>0.900835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.824995</td>\n",
       "      <td>0.074642</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.850443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.826702</td>\n",
       "      <td>0.087498</td>\n",
       "      <td>0.368503</td>\n",
       "      <td>0.873033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.827607</td>\n",
       "      <td>0.092553</td>\n",
       "      <td>0.367908</td>\n",
       "      <td>0.951754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.824921</td>\n",
       "      <td>0.086709</td>\n",
       "      <td>0.368838</td>\n",
       "      <td>0.872113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.827004</td>\n",
       "      <td>0.085995</td>\n",
       "      <td>0.368734</td>\n",
       "      <td>0.857507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.828781</td>\n",
       "      <td>0.081810</td>\n",
       "      <td>0.367995</td>\n",
       "      <td>0.847951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.824392</td>\n",
       "      <td>0.100523</td>\n",
       "      <td>0.370887</td>\n",
       "      <td>0.884766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Split  Lam_fair   Type  Accuracy  Unfairness     Ploss  Relaxation\n",
       "0     0       0.0  Train  0.827890    0.081045  0.364729    0.907473\n",
       "1     0       0.0   Test  0.822383    0.086585  0.377499    0.949487\n",
       "2     1       0.0  Train  0.827098    0.085512  0.367405    0.900835\n",
       "3     1       0.0   Test  0.824995    0.074642  0.372423    0.850443\n",
       "4     2       0.0  Train  0.826702    0.087498  0.368503    0.873033\n",
       "5     2       0.0   Test  0.827607    0.092553  0.367908    0.951754\n",
       "6     3       0.0  Train  0.824921    0.086709  0.368838    0.872113\n",
       "7     3       0.0   Test  0.827004    0.085995  0.368734    0.857507\n",
       "8     4       0.0  Train  0.828781    0.081810  0.367995    0.847951\n",
       "9     4       0.0   Test  0.824392    0.100523  0.370887    0.884766"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
